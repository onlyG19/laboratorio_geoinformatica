#!/bin/bash

# =============================================================================
# Setup Script para Laboratorio Integrador de GeoinformÃ¡tica
# =============================================================================

set -e  # Detener si hay errores

# Colores para output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Banner
echo -e "${BLUE}"
echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘         LABORATORIO INTEGRADOR - GEOINFORMÃTICA                   â•‘"
echo "â•‘              ConfiguraciÃ³n Inicial del Proyecto                   â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo -e "${NC}"

# FunciÃ³n para imprimir mensajes con color
print_message() {
    echo -e "${GREEN}[âœ“]${NC} $1"
}

print_error() {
    echo -e "${RED}[âœ—]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[!]${NC} $1"
}

# Verificar prerrequisitos
echo -e "${BLUE}Verificando prerrequisitos...${NC}"

# Verificar Docker
if command -v docker &> /dev/null; then
    print_message "Docker instalado: $(docker --version)"
else
    print_error "Docker no estÃ¡ instalado. Por favor instale Docker Desktop."
    exit 1
fi

# Verificar Docker Compose
if command -v docker-compose &> /dev/null; then
    print_message "Docker Compose instalado: $(docker-compose --version)"
else
    print_error "Docker Compose no estÃ¡ instalado."
    exit 1
fi

# Verificar Python
if command -v python3 &> /dev/null; then
    print_message "Python instalado: $(python3 --version)"
else
    print_error "Python 3 no estÃ¡ instalado."
    exit 1
fi

# Verificar Git
if command -v git &> /dev/null; then
    print_message "Git instalado: $(git --version)"
else
    print_warning "Git no estÃ¡ instalado. Se recomienda instalarlo para control de versiones."
fi

echo ""
echo -e "${BLUE}Creando estructura de directorios...${NC}"

# Crear directorios principales
directories=(
    "data/raw"
    "data/processed"
    "data/external"
    "notebooks"
    "scripts"
    "app/pages"
    "app/components"
    "app/static"
    "outputs/figures"
    "outputs/models"
    "outputs/reports"
    "docker/jupyter"
    "docker/postgis"
    "docker/web"
    "tests"
)

for dir in "${directories[@]}"; do
    mkdir -p "$dir"
    print_message "Directorio creado: $dir"
done

echo ""
echo -e "${BLUE}Creando archivos de configuraciÃ³n...${NC}"

# Crear archivo .env
if [ ! -f .env ]; then
    cat > .env << 'EOF'
# Database Configuration
POSTGRES_DB=geodatabase
POSTGRES_USER=geouser
POSTGRES_PASSWORD=geopass
POSTGRES_HOST=localhost
POSTGRES_PORT=5432

# Jupyter Configuration
JUPYTER_TOKEN=laboratorio2025
JUPYTER_PORT=8888

# Web App Configuration
STREAMLIT_PORT=5000

# Project Configuration
COMUNA_NAME=
PROJECT_NAME=laboratorio_integrador

# API Keys (agregar si es necesario)
# GOOGLE_EARTH_ENGINE_KEY=
# SENTINEL_HUB_KEY=

# Paths
DATA_DIR=./data
OUTPUT_DIR=./outputs
EOF
    print_message "Archivo .env creado"
else
    print_warning "Archivo .env ya existe, no se sobrescribe"
fi

# Crear .gitignore
cat > .gitignore << 'EOF'
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
venv/
ENV/
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Jupyter Notebook
.ipynb_checkpoints
*/.ipynb_checkpoints/*

# Environment
.env
.venv

# Data files
data/raw/*
data/processed/*
data/external/*
*.tif
*.tiff
*.shp
*.shx
*.dbf
*.prj
*.cpg
*.gpkg
*.geojson
*.csv
!data/raw/.gitkeep
!data/processed/.gitkeep
!data/external/.gitkeep

# Models
*.pkl
*.h5
*.pt
*.pth
*.joblib

# Outputs
outputs/figures/*
outputs/models/*
outputs/reports/*
!outputs/figures/.gitkeep
!outputs/models/.gitkeep
!outputs/reports/.gitkeep

# OS
.DS_Store
Thumbs.db
desktop.ini

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# Docker
.dockerignore

# Logs
*.log
logs/

# Temporary files
*.tmp
*.temp
tmp/
temp/
EOF
print_message "Archivo .gitignore creado"

# Crear archivos .gitkeep para mantener directorios vacÃ­os
touch data/raw/.gitkeep
touch data/processed/.gitkeep
touch data/external/.gitkeep
touch outputs/figures/.gitkeep
touch outputs/models/.gitkeep
touch outputs/reports/.gitkeep

echo ""
echo -e "${BLUE}Creando Docker Compose...${NC}"

# Crear docker-compose.yml
cat > docker-compose.yml << 'EOF'
version: '3.8'

services:
  postgis:
    image: postgis/postgis:15-3.3-alpine
    container_name: postgis_lab
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./docker/postgis/init.sql:/docker-entrypoint-initdb.d/01-init.sql
    ports:
      - "${POSTGRES_PORT}:5432"
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5

  jupyter:
    build: ./docker/jupyter
    container_name: jupyter_lab
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - JUPYTER_TOKEN=${JUPYTER_TOKEN}
      - POSTGRES_HOST=postgis
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./data:/home/jovyan/data
      - ./scripts:/home/jovyan/scripts
      - ./outputs:/home/jovyan/outputs
    ports:
      - "${JUPYTER_PORT}:8888"
    depends_on:
      postgis:
        condition: service_healthy
    restart: unless-stopped

  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: pgadmin_lab
    environment:
      - PGADMIN_DEFAULT_EMAIL=admin@geoinformatica.cl
      - PGADMIN_DEFAULT_PASSWORD=admin
    ports:
      - "5050:80"
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    depends_on:
      - postgis
    restart: unless-stopped

volumes:
  postgres_data:
  pgadmin_data:
EOF
print_message "docker-compose.yml creado"

echo ""
echo -e "${BLUE}Creando Dockerfiles...${NC}"

# Dockerfile para Jupyter
cat > docker/jupyter/Dockerfile << 'EOF'
FROM jupyter/scipy-notebook:latest

USER root

# Instalar dependencias del sistema
RUN apt-get update && apt-get install -y \
    gdal-bin \
    libgdal-dev \
    libspatialindex-dev \
    libproj-dev \
    libgeos-dev \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# Configurar GDAL
ENV GDAL_CONFIG=/usr/bin/gdal-config
ENV PROJ_LIB=/usr/share/proj

USER $NB_UID

# Copiar requirements
COPY requirements.txt /tmp/

# Instalar librerÃ­as Python
RUN pip install --no-cache-dir -r /tmp/requirements.txt && \
    fix-permissions "${CONDA_DIR}" && \
    fix-permissions "/home/${NB_USER}"

# Instalar extensiones de JupyterLab
RUN jupyter labextension install @jupyter-widgets/jupyterlab-manager \
    jupyterlab-plotly \
    @jupyterlab/geojson-extension

WORKDIR /home/jovyan/work
EOF
print_message "Dockerfile para Jupyter creado"

# requirements.txt para Jupyter
cat > docker/jupyter/requirements.txt << 'EOF'
# Geospatial Core
geopandas==0.14.1
shapely==2.0.2
pyproj==3.6.1
rasterio==1.3.9
fiona==1.9.5
rtree==1.1.0
osmnx==1.8.0
contextily==1.4.0
geopy==2.4.1

# Data Science
pandas==2.1.4
numpy==1.24.3
scipy==1.11.4
scikit-learn==1.3.2
xgboost==2.0.2
lightgbm==4.1.0

# Spatial Analysis
pysal==23.7
esda==2.5.1
splot==1.1.5.post1
libpysal==4.9.2
momepy==0.6.0
pointpats==2.4.0

# Geostatistics
scikit-gstat==1.0.15
pykrige==1.7.0

# Visualization
matplotlib==3.8.2
seaborn==0.13.0
plotly==5.18.0
folium==0.15.1
ipyleaflet==0.18.1
bokeh==3.3.2
altair==5.2.0

# Database
psycopg2-binary==2.9.9
sqlalchemy==2.0.23
geoalchemy2==0.14.3

# Image Processing
scikit-image==0.22.0
opencv-python==4.8.1.78
earthpy==0.9.4

# Web and APIs
requests==2.31.0
beautifulsoup4==4.12.2
lxml==4.9.4

# Google Earth Engine
earthengine-api==0.1.381
geemap==0.29.6

# Utilities
tqdm==4.66.1
python-dotenv==1.0.0
click==8.1.7
pyyaml==6.0.1
h3==3.7.6

# ML Interpretability
shap==0.43.0
lime==0.2.0.1

# Jupyter Extensions
ipywidgets==8.1.1
jupyterlab==4.0.9
notebook==7.0.6
EOF
print_message "requirements.txt para Jupyter creado"

# Script de inicializaciÃ³n para PostGIS
cat > docker/postgis/init.sql << 'EOF'
-- Crear extensiones espaciales
CREATE EXTENSION IF NOT EXISTS postgis;
CREATE EXTENSION IF NOT EXISTS postgis_topology;
CREATE EXTENSION IF NOT EXISTS postgis_raster;
CREATE EXTENSION IF NOT EXISTS pgrouting;
CREATE EXTENSION IF NOT EXISTS fuzzystrmatch;
CREATE EXTENSION IF NOT EXISTS postgis_tiger_geocoder;
CREATE EXTENSION IF NOT EXISTS address_standardizer;

-- Crear esquemas
CREATE SCHEMA IF NOT EXISTS raw_data;
CREATE SCHEMA IF NOT EXISTS processed;
CREATE SCHEMA IF NOT EXISTS analysis;

-- Tabla de metadatos del proyecto
CREATE TABLE IF NOT EXISTS public.project_metadata (
    id SERIAL PRIMARY KEY,
    key VARCHAR(255) UNIQUE NOT NULL,
    value TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Insertar metadatos iniciales
INSERT INTO project_metadata (key, value) VALUES
    ('project_name', 'Laboratorio Integrador'),
    ('version', '1.0.0'),
    ('created_date', CURRENT_DATE::TEXT),
    ('srid', '32719'); -- UTM Zone 19S para Chile

-- FunciÃ³n para actualizar timestamp
CREATE OR REPLACE FUNCTION update_updated_at()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = CURRENT_TIMESTAMP;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Trigger para actualizaciÃ³n automÃ¡tica
CREATE TRIGGER update_project_metadata_updated_at
    BEFORE UPDATE ON project_metadata
    FOR EACH ROW
    EXECUTE FUNCTION update_updated_at();

-- Tabla de log de procesos
CREATE TABLE IF NOT EXISTS public.process_log (
    id SERIAL PRIMARY KEY,
    process_name VARCHAR(255),
    status VARCHAR(50),
    message TEXT,
    started_at TIMESTAMP,
    finished_at TIMESTAMP,
    created_by VARCHAR(100) DEFAULT CURRENT_USER
);

-- Vista de informaciÃ³n espacial
CREATE OR REPLACE VIEW spatial_info AS
SELECT
    f_table_schema as schema,
    f_table_name as table_name,
    f_geometry_column as geom_column,
    coord_dimension,
    srid,
    type
FROM geometry_columns
ORDER BY f_table_schema, f_table_name;

-- Mensaje de confirmaciÃ³n
DO $$
BEGIN
    RAISE NOTICE 'PostGIS configurado exitosamente!';
    RAISE NOTICE 'VersiÃ³n: %', PostGIS_Version();
END $$;
EOF
print_message "Script SQL de inicializaciÃ³n creado"

echo ""
echo -e "${BLUE}Creando requirements.txt principal...${NC}"

# requirements.txt principal
cat > requirements.txt << 'EOF'
# Core Geospatial
geopandas>=0.14.0
shapely>=2.0.0
pyproj>=3.6.0
rasterio>=1.3.0
fiona>=1.9.0
osmnx>=1.8.0

# Data Science
pandas>=2.1.0
numpy>=1.24.0
scikit-learn>=1.3.0
xgboost>=2.0.0

# Spatial Analysis
pysal>=23.0
esda>=2.5.0
splot>=1.1.5

# Visualization
matplotlib>=3.8.0
seaborn>=0.13.0
plotly>=5.18.0
folium>=0.15.0
streamlit>=1.29.0
streamlit-folium>=0.17.0

# Database
psycopg2-binary>=2.9.0
sqlalchemy>=2.0.0
geoalchemy2>=0.14.0

# Utilities
python-dotenv>=1.0.0
tqdm>=4.66.0
click>=8.1.0
EOF
print_message "requirements.txt principal creado"

echo ""
echo -e "${BLUE}Creando scripts de ejemplo...${NC}"

# Script de descarga de datos
cat > scripts/download_data.py << 'EOF'
#!/usr/bin/env python3
"""
Script para descargar datos geoespaciales de la comuna seleccionada.
"""

import os
import sys
import click
import requests
import geopandas as gpd
import osmnx as ox
from pathlib import Path
from datetime import datetime
import logging

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class DataDownloader:
    """Clase para gestionar la descarga de datos geoespaciales."""

    def __init__(self, comuna_name: str, output_dir: Path):
        self.comuna = comuna_name
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        logger.info(f"Inicializando descarga para comuna: {comuna_name}")

    def download_osm_data(self):
        """Descarga datos de OpenStreetMap usando OSMnx."""
        try:
            logger.info("Descargando red vial desde OSM...")

            # Configurar OSMnx
            ox.config(use_cache=True, log_console=True)

            # Descargar red vial
            place_query = f"{self.comuna}, Chile"
            G = ox.graph_from_place(place_query, network_type='all')

            # Guardar grafo
            output_file = self.output_dir / 'osm_network.graphml'
            ox.save_graphml(G, output_file)
            logger.info(f"Red vial guardada en: {output_file}")

            # Descargar edificios
            logger.info("Descargando edificios...")
            buildings = ox.geometries_from_place(
                place_query,
                tags={'building': True}
            )

            # Guardar edificios
            buildings_file = self.output_dir / 'osm_buildings.geojson'
            buildings.to_file(buildings_file, driver='GeoJSON')
            logger.info(f"Edificios guardados en: {buildings_file}")

            # Descargar amenidades
            logger.info("Descargando amenidades...")
            amenities = ox.geometries_from_place(
                place_query,
                tags={'amenity': True}
            )

            amenities_file = self.output_dir / 'osm_amenities.geojson'
            amenities.to_file(amenities_file, driver='GeoJSON')
            logger.info(f"Amenidades guardadas en: {amenities_file}")

            return True

        except Exception as e:
            logger.error(f"Error descargando datos OSM: {e}")
            return False

    def download_boundaries(self):
        """Descarga lÃ­mites administrativos de IDE Chile."""
        try:
            logger.info("Descargando lÃ­mites administrativos...")

            # URL del servicio WFS de IDE Chile (ejemplo)
            wfs_url = "https://www.ide.cl/geoserver/wfs"

            # ParÃ¡metros para la peticiÃ³n
            params = {
                'service': 'WFS',
                'version': '2.0.0',
                'request': 'GetFeature',
                'typeName': 'division_comunal',
                'outputFormat': 'application/json',
                'CQL_FILTER': f"comuna='{self.comuna.upper()}'"
            }

            # Realizar peticiÃ³n
            response = requests.get(wfs_url, params=params)

            if response.status_code == 200:
                # Guardar respuesta
                boundaries_file = self.output_dir / 'comuna_boundaries.geojson'
                with open(boundaries_file, 'w') as f:
                    f.write(response.text)
                logger.info(f"LÃ­mites guardados en: {boundaries_file}")
                return True
            else:
                logger.warning("No se pudieron descargar lÃ­mites de IDE Chile")
                return False

        except Exception as e:
            logger.error(f"Error descargando lÃ­mites: {e}")
            return False

    def create_metadata(self):
        """Crea archivo de metadatos de la descarga."""
        metadata = {
            'comuna': self.comuna,
            'fecha_descarga': datetime.now().isoformat(),
            'fuentes': ['OpenStreetMap', 'IDE Chile'],
            'archivos_generados': list(self.output_dir.glob('*'))
        }

        metadata_file = self.output_dir / 'metadata.txt'
        with open(metadata_file, 'w') as f:
            for key, value in metadata.items():
                f.write(f"{key}: {value}\n")

        logger.info(f"Metadatos guardados en: {metadata_file}")


@click.command()
@click.option('--comuna', required=True, help='Nombre de la comuna')
@click.option('--output', default='../data/raw', help='Directorio de salida')
@click.option('--sources', default='all', help='Fuentes a descargar (osm,ide,all)')
def main(comuna, output, sources):
    """Script principal para descarga de datos."""

    logger.info("=" * 50)
    logger.info("INICIANDO DESCARGA DE DATOS")
    logger.info("=" * 50)

    downloader = DataDownloader(comuna, Path(output))

    # Descargar segÃºn las fuentes especificadas
    if sources in ['osm', 'all']:
        downloader.download_osm_data()

    if sources in ['ide', 'all']:
        downloader.download_boundaries()

    # Crear metadatos
    downloader.create_metadata()

    logger.info("Descarga completada exitosamente!")


if __name__ == '__main__':
    main()
EOF
print_message "Script de descarga de datos creado"

# Script de procesamiento
cat > scripts/process_data.py << 'EOF'
#!/usr/bin/env python3
"""
Script para procesar y preparar datos para anÃ¡lisis.
"""

import geopandas as gpd
import pandas as pd
from pathlib import Path
from sqlalchemy import create_engine
import logging
import os
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class DataProcessor:
    """Procesa y prepara datos para anÃ¡lisis."""

    def __init__(self):
        self.engine = self.create_db_connection()

    def create_db_connection(self):
        """Crea conexiÃ³n a PostGIS."""
        db_url = (
            f"postgresql://{os.getenv('POSTGRES_USER')}:"
            f"{os.getenv('POSTGRES_PASSWORD')}@"
            f"{os.getenv('POSTGRES_HOST', 'localhost')}:"
            f"{os.getenv('POSTGRES_PORT', '5432')}/"
            f"{os.getenv('POSTGRES_DB')}"
        )
        return create_engine(db_url)

    def load_to_postgis(self, gdf, table_name, schema='raw_data'):
        """Carga GeoDataFrame a PostGIS."""
        try:
            gdf.to_postgis(
                table_name,
                self.engine,
                schema=schema,
                if_exists='replace',
                index=False
            )
            logger.info(f"Tabla {schema}.{table_name} creada exitosamente")
            return True
        except Exception as e:
            logger.error(f"Error cargando a PostGIS: {e}")
            return False

    def process_osm_network(self, input_file):
        """Procesa red vial de OSM."""
        logger.info("Procesando red vial...")
        # Implementar procesamiento
        pass

    def create_spatial_indices(self):
        """Crea Ã­ndices espaciales en las tablas."""
        logger.info("Creando Ã­ndices espaciales...")
        # Implementar creaciÃ³n de Ã­ndices
        pass


def main():
    processor = DataProcessor()
    # Implementar lÃ³gica principal
    logger.info("Procesamiento completado!")


if __name__ == '__main__':
    main()
EOF
print_message "Script de procesamiento creado"

echo ""
echo -e "${BLUE}Creando aplicaciÃ³n Streamlit de ejemplo...${NC}"

# App principal Streamlit
cat > app/main.py << 'EOF'
"""
AplicaciÃ³n web para visualizaciÃ³n de anÃ¡lisis geoespacial.
"""

import streamlit as st
import pandas as pd
import geopandas as gpd
import folium
from streamlit_folium import st_folium
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
import os
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv()

# ConfiguraciÃ³n de la pÃ¡gina
st.set_page_config(
    page_title="AnÃ¡lisis Territorial - Laboratorio Integrador",
    page_icon="ğŸ—ºï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personalizado
st.markdown("""
    <style>
    .main {
        padding-top: 2rem;
    }
    .stButton>button {
        background-color: #0066CC;
        color: white;
    }
    .st-emotion-cache-16idsys p {
        font-size: 1.1rem;
    }
    </style>
""", unsafe_allow_html=True)

# TÃ­tulo principal
st.title("ğŸ—ºï¸ Sistema de AnÃ¡lisis Territorial")
st.markdown(f"### Comuna: {os.getenv('COMUNA_NAME', 'No configurada')}")

# Sidebar
with st.sidebar:
    st.image("https://via.placeholder.com/300x100?text=Logo+USACH", width=300)
    st.markdown("---")

    st.markdown("### ğŸ“Š NavegaciÃ³n")
    page = st.selectbox(
        "Seleccione una secciÃ³n:",
        ["ğŸ  Inicio", "ğŸ“Š Datos", "ğŸ—ºï¸ AnÃ¡lisis Espacial",
         "ğŸ¤– Machine Learning", "ğŸ“ˆ Resultados"]
    )

    st.markdown("---")
    st.markdown("### â„¹ï¸ InformaciÃ³n")
    st.info(
        """
        **Laboratorio Integrador**

        GeoinformÃ¡tica 2025

        USACH
        """
    )

# Contenido principal segÃºn pÃ¡gina seleccionada
if page == "ğŸ  Inicio":
    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric("Ãrea Total", "125.4 kmÂ²", "+2.3%")

    with col2:
        st.metric("PoblaciÃ³n", "245,678", "+5.2%")

    with col3:
        st.metric("Densidad", "1,958 hab/kmÂ²", "+2.8%")

    st.markdown("---")

    # Mapa principal
    st.subheader("ğŸ“ UbicaciÃ³n de la Comuna")

    # Crear mapa con Folium
    m = folium.Map(
        location=[-33.45, -70.65],  # Santiago
        zoom_start=11,
        tiles='OpenStreetMap'
    )

    # Agregar marcador
    folium.Marker(
        [-33.45, -70.65],
        popup="Centro de la Comuna",
        tooltip="Click para mÃ¡s info",
        icon=folium.Icon(icon="info-sign", color="red")
    ).add_to(m)

    # Mostrar mapa
    st_folium(m, height=500, width=None, returned_objects=["last_clicked"])

elif page == "ğŸ“Š Datos":
    st.header("ğŸ“Š ExploraciÃ³n de Datos")

    tab1, tab2, tab3 = st.tabs(["ğŸ“‹ Resumen", "ğŸ“ˆ EstadÃ­sticas", "ğŸ—‚ï¸ Metadatos"])

    with tab1:
        st.subheader("Fuentes de Datos Integradas")

        data_sources = pd.DataFrame({
            'Fuente': ['OpenStreetMap', 'INE', 'IDE Chile', 'Sentinel-2', 'SRTM DEM'],
            'Tipo': ['Vectorial', 'Tabular', 'Vectorial', 'Raster', 'Raster'],
            'Ãšltima ActualizaciÃ³n': ['2024-01', '2023-12', '2024-01', '2024-01', '2023-06'],
            'Estado': ['âœ… Cargado', 'âœ… Cargado', 'â³ Pendiente', 'â³ Pendiente', 'âœ… Cargado']
        })

        st.dataframe(data_sources, use_container_width=True)

    with tab2:
        st.subheader("EstadÃ­sticas Descriptivas")

        # GrÃ¡fico de ejemplo
        fig = px.bar(
            x=['Residencial', 'Comercial', 'Industrial', 'Ãreas Verdes', 'Otros'],
            y=[45, 20, 15, 12, 8],
            labels={'x': 'Uso del Suelo', 'y': 'Porcentaje (%)'},
            title='DistribuciÃ³n de Uso del Suelo'
        )
        st.plotly_chart(fig, use_container_width=True)

    with tab3:
        st.subheader("Metadatos del Proyecto")
        st.json({
            'proyecto': 'Laboratorio Integrador',
            'version': '1.0.0',
            'fecha_creacion': '2024-01-15',
            'ultima_actualizacion': '2024-01-20',
            'crs': 'EPSG:32719',
            'formato_datos': ['GeoJSON', 'Shapefile', 'GeoTIFF', 'CSV']
        })

elif page == "ğŸ—ºï¸ AnÃ¡lisis Espacial":
    st.header("ğŸ—ºï¸ AnÃ¡lisis Espacial")

    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("AutocorrelaciÃ³n Espacial - Moran's I")

        # Placeholder para grÃ¡fico
        st.info("AquÃ­ se mostrarÃ¡ el anÃ¡lisis de autocorrelaciÃ³n espacial")

    with col2:
        st.subheader("MÃ©tricas")
        st.metric("Moran's I Global", "0.642", "Alto clustering")
        st.metric("P-value", "0.001", "Significativo")
        st.metric("Z-score", "15.23", "")

elif page == "ğŸ¤– Machine Learning":
    st.header("ğŸ¤– Modelos de Machine Learning")

    model_type = st.selectbox(
        "Seleccione el modelo:",
        ["Random Forest", "XGBoost", "Red Neuronal"]
    )

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("ParÃ¡metros del Modelo")

        if model_type == "Random Forest":
            n_estimators = st.slider("NÃºmero de Ã¡rboles:", 10, 500, 100)
            max_depth = st.slider("Profundidad mÃ¡xima:", 1, 20, 5)
            min_samples_split = st.slider("Min samples split:", 2, 20, 2)

    with col2:
        st.subheader("MÃ©tricas de Rendimiento")
        st.metric("RÂ² Score", "0.872")
        st.metric("RMSE", "12.34")
        st.metric("MAE", "8.76")

    if st.button("ğŸš€ Entrenar Modelo"):
        with st.spinner("Entrenando modelo..."):
            st.success("Modelo entrenado exitosamente!")

elif page == "ğŸ“ˆ Resultados":
    st.header("ğŸ“ˆ SÃ­ntesis de Resultados")

    st.markdown("""
    ### Hallazgos Principales

    1. **PatrÃ³n espacial identificado**: Se detectÃ³ clustering significativo en las variables socioeconÃ³micas
    2. **PredicciÃ³n exitosa**: El modelo ML alcanzÃ³ un RÂ² de 0.87
    3. **Zonas crÃ­ticas**: Se identificaron 5 hot spots que requieren atenciÃ³n

    ### Recomendaciones

    - Implementar polÃ­ticas focalizadas en las zonas identificadas
    - Continuar monitoreo con imÃ¡genes satelitales actualizadas
    - Expandir el anÃ¡lisis a comunas vecinas
    """)

    # BotÃ³n de descarga
    st.download_button(
        label="ğŸ“¥ Descargar Informe Completo (PDF)",
        data=b"Contenido del PDF aquÃ­",
        file_name="informe_analisis_territorial.pdf",
        mime="application/pdf"
    )

# Footer
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center'>
        <p>Desarrollado para el curso de GeoinformÃ¡tica - USACH 2025</p>
        <p>Prof. Francisco Parra O. | <a href='mailto:francisco.parra.o@usach.cl'>francisco.parra.o@usach.cl</a></p>
    </div>
    """,
    unsafe_allow_html=True
)
EOF
print_message "AplicaciÃ³n Streamlit creada"

echo ""
echo -e "${BLUE}Creando notebook de ejemplo...${NC}"

# Crear directorio y archivo Python que luego convertiremos
cat > notebooks/00_template.py << 'EOF'
# ---
# jupyter:
#   jupytext:
#     text_representation:
#       extension: .py
#       format_name: light
#       format_version: '1.5'
#       jupytext_version: 1.14.0
#   kernelspec:
#     display_name: Python 3
#     language: python
#     name: python3
# ---

# # Notebook Template - Laboratorio Integrador
#
# Este notebook sirve como plantilla para los anÃ¡lisis del laboratorio.

# ## 1. ConfiguraciÃ³n Inicial

import warnings
warnings.filterwarnings('ignore')

import os
import sys
from pathlib import Path

# Agregar scripts al path
sys.path.append('../scripts')

# LibrerÃ­as principales
import pandas as pd
import numpy as np
import geopandas as gpd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

# ConfiguraciÃ³n de visualizaciÃ³n
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# Configurar pandas
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', 100)

print(f"Ambiente configurado: {datetime.now()}")
print(f"Python version: {sys.version}")

# ## 2. DefiniciÃ³n de Paths

# Paths principales
DATA_DIR = Path('../data')
RAW_DATA = DATA_DIR / 'raw'
PROCESSED_DATA = DATA_DIR / 'processed'
OUTPUT_DIR = Path('../outputs')
FIGURES_DIR = OUTPUT_DIR / 'figures'
MODELS_DIR = OUTPUT_DIR / 'models'

# Verificar que existan
for path in [DATA_DIR, OUTPUT_DIR]:
    if not path.exists():
        print(f"âš ï¸ Directorio no existe: {path}")
    else:
        print(f"âœ… Directorio encontrado: {path}")

# ## 3. ConexiÃ³n a Base de Datos

from sqlalchemy import create_engine
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv()

# Crear conexiÃ³n a PostGIS
def create_db_connection():
    """Crea conexiÃ³n a la base de datos PostGIS."""
    try:
        engine = create_engine(
            f"postgresql://{os.getenv('POSTGRES_USER')}:"
            f"{os.getenv('POSTGRES_PASSWORD')}@"
            f"localhost:{os.getenv('POSTGRES_PORT')}/"
            f"{os.getenv('POSTGRES_DB')}"
        )
        print("âœ… ConexiÃ³n a PostGIS exitosa")
        return engine
    except Exception as e:
        print(f"âŒ Error conectando a PostGIS: {e}")
        return None

engine = create_db_connection()

# ## 4. Funciones Auxiliares

def load_geodata(filepath):
    """Carga archivo geoespacial."""
    try:
        gdf = gpd.read_file(filepath)
        print(f"âœ… Cargado: {filepath.name}")
        print(f"   Registros: {len(gdf)}")
        print(f"   CRS: {gdf.crs}")
        return gdf
    except Exception as e:
        print(f"âŒ Error cargando {filepath}: {e}")
        return None

def save_figure(fig, name, dpi=300):
    """Guarda figura en alta resoluciÃ³n."""
    filepath = FIGURES_DIR / f"{name}.png"
    fig.savefig(filepath, dpi=dpi, bbox_inches='tight')
    print(f"ğŸ“Š Figura guardada: {filepath}")

def calculate_statistics(gdf, column):
    """Calcula estadÃ­sticas descriptivas para una columna."""
    stats = {
        'count': gdf[column].count(),
        'mean': gdf[column].mean(),
        'std': gdf[column].std(),
        'min': gdf[column].min(),
        '25%': gdf[column].quantile(0.25),
        '50%': gdf[column].median(),
        '75%': gdf[column].quantile(0.75),
        'max': gdf[column].max()
    }
    return pd.Series(stats)

# ## 5. Carga de Datos de Ejemplo

# Intentar cargar datos si existen
sample_file = RAW_DATA / 'sample_data.geojson'
if sample_file.exists():
    gdf = load_geodata(sample_file)
    if gdf is not None:
        print("\nPrimeras filas:")
        print(gdf.head())
else:
    print("â„¹ï¸ No hay datos de ejemplo disponibles")

# ## 6. AnÃ¡lisis Exploratorio BÃ¡sico

if 'gdf' in locals() and gdf is not None:
    # InformaciÃ³n general
    print("\nğŸ“Š InformaciÃ³n del Dataset:")
    print(f"Filas: {len(gdf)}")
    print(f"Columnas: {len(gdf.columns)}")
    print(f"Tipos de geometrÃ­a: {gdf.geometry.type.unique()}")

    # VisualizaciÃ³n bÃ¡sica
    fig, ax = plt.subplots(figsize=(10, 10))
    gdf.plot(ax=ax, edgecolor='black', facecolor='lightblue', alpha=0.7)
    ax.set_title('Vista General de la Comuna', fontsize=16)
    ax.set_xlabel('Longitud')
    ax.set_ylabel('Latitud')
    plt.tight_layout()
    plt.show()

# ## 7. PrÃ³ximos Pasos

print("\nğŸ“ PrÃ³ximos pasos sugeridos:")
print("1. Cargar datos especÃ­ficos de la comuna")
print("2. Realizar anÃ¡lisis exploratorio completo")
print("3. Aplicar tÃ©cnicas de anÃ¡lisis espacial")
print("4. Desarrollar modelos de ML")
print("5. Crear visualizaciones para el dashboard")

# ## 8. InformaciÃ³n de la SesiÃ³n

print("\n" + "="*50)
print("INFORMACIÃ“N DE LA SESIÃ“N")
print("="*50)
print(f"Fecha y hora: {datetime.now()}")
print(f"Usuario: {os.getenv('USER', 'unknown')}")
print(f"Comuna analizada: {os.getenv('COMUNA_NAME', 'No configurada')}")
print(f"Directorio de trabajo: {os.getcwd()}")
EOF
print_message "Notebook de ejemplo creado"

echo ""
echo -e "${BLUE}Finalizando configuraciÃ³n...${NC}"

# Crear archivo de variables de entorno de ejemplo
cat > .env.example << 'EOF'
# Database Configuration
POSTGRES_DB=geodatabase
POSTGRES_USER=geouser
POSTGRES_PASSWORD=geopass
POSTGRES_HOST=localhost
POSTGRES_PORT=5432

# Jupyter Configuration
JUPYTER_TOKEN=laboratorio2025
JUPYTER_PORT=8888

# Web App Configuration
STREAMLIT_PORT=5000

# Project Configuration
COMUNA_NAME=Your_Comuna_Here
PROJECT_NAME=laboratorio_integrador

# API Keys (optional)
# GOOGLE_EARTH_ENGINE_KEY=your_key_here
# SENTINEL_HUB_KEY=your_key_here
EOF
print_message "Archivo .env.example creado"

# Hacer el script ejecutable
chmod +x scripts/*.py 2>/dev/null

echo ""
echo -e "${GREEN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
echo -e "${GREEN}â•‘                   CONFIGURACIÃ“N COMPLETADA âœ“                      â•‘${NC}"
echo -e "${GREEN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"

echo ""
echo -e "${BLUE}PrÃ³ximos pasos:${NC}"
echo ""
echo "1. Editar el archivo .env con los valores de su proyecto:"
echo -e "   ${YELLOW}nano .env${NC}"
echo ""
echo "2. Iniciar los servicios Docker:"
echo -e "   ${YELLOW}docker-compose up -d${NC}"
echo ""
echo "3. Verificar que los servicios estÃ©n corriendo:"
echo -e "   ${YELLOW}docker-compose ps${NC}"
echo ""
echo "4. Acceder a Jupyter Lab:"
echo -e "   ${YELLOW}http://localhost:8888${NC}"
echo "   Token: laboratorio2025 (o el configurado en .env)"
echo ""
echo "5. Acceder a PgAdmin:"
echo -e "   ${YELLOW}http://localhost:5050${NC}"
echo "   Email: admin@geoinformatica.cl"
echo "   Password: admin"
echo ""
echo "6. Para detener los servicios:"
echo -e "   ${YELLOW}docker-compose down${NC}"
echo ""
echo -e "${GREEN}Â¡Buena suerte con su proyecto!${NC} ğŸš€"